# awesome-sharpness-aware-minimization

1. [SAM] Sharpness-Aware Minimization for Efficiently Improving Generalization. Pierre Foret, Ariel Kleiner, Hossein Mobahi, Behnam Neyshabur
2. (Effectiveness)[ASAM] ASAM: Adaptive Sharpness-Aware Minimization for Scale-Invariant Learning of Deep Neural Networks. Jungmin Kwon, Jeongseop Kim, Hyunseo Park, In Kwon Choi
3. (Efficiency)[ESAM] Efficient Sharpness-aware Minimization for Improved Training of Neural Networks. Jiawei Du, Hanshu Yan, Jiashi Feng, Joey Tianyi Zhou, Liangli Zhen, Rick Siow Mong Goh, Vincent Y. F. Tan
4. (Efficiency)[LookSAM] Towards Efficient and Scalable Sharpness-Aware Minimization. Yong Liu, Siqi Mai, Xiangning Chen, Cho-Jui Hsieh, Yang You
5. (Effectiveness)[GSAM] Surrogate Gap Guided Sharpness-Aware Minimization. Juntang Zhuang, Boqing Gong, Liangzhe Yuan, Yin Cui, Hartwig Adam, Nicha Dvornek, Sekhar Tatikonda, James Duncan, Ting Liu
6. (Efficiency)[K-SAM] K-SAM: Sharpness-Aware Minimization at the Speed of SGD. Renkun Ni, Ping-yeh Chiang, Jonas Geiping, Micah Goldblum, Andrew Gordon Wilson, Tom Goldstein
7. (Efficiency)[RSAM] Random Sharpness-Aware Minimization. Yong Liu, Siqi Mai, Minhao Cheng, Xiangning Chen, Cho-Jui Hsieh, Yang You
8. (Efficiency)[SS-SAM] Randomized Sharpness-Aware Training for Boosting Computational Efficiency in Deep Learning. Yang Zhao, Hao Zhang, Xiuyuan Hu.
9. (Efficiency)[AE-SAM] An Adaptive Policy to Employ Sharpness-Aware Minimization. Weisen Jiang, Hansi Yang, Yu Zhang, James Kwok
10. (Efficiency)[SSAM] Make Sharpness-Aware Minimization Stronger: A Sparsified Perturbation Approach. Peng Mi, Li Shen, Tianhe Ren, Yiyi Zhou, Xiaoshuai Sun, Rongrong Ji, Dacheng Tao.
11. (Effectiveness)[CR-SAM] CR-SAM: Curvature Regularized Sharpness-Aware Minimization. Tao Wu, Tie Luo1, Donald C. Wunsch II.
